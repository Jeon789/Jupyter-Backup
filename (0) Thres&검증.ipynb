{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.8.1+cu102 in /opt/conda/lib/python3.7/site-packages (1.8.1+cu102)\n",
      "Requirement already satisfied: torchvision==0.9.1+cu102 in /opt/conda/lib/python3.7/site-packages (0.9.1+cu102)\n",
      "Requirement already satisfied: torchaudio===0.8.1 in /opt/conda/lib/python3.7/site-packages (0.8.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.8.1+cu102) (3.10.0.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch==1.8.1+cu102) (1.18.4)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.9.1+cu102) (7.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch==1.8.1+cu102 torchvision==0.9.1+cu102 torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from model_resnet import ResNet\n",
    "from model_resnet import ResidualBlock\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = ResNet(ResidualBlock, [2, 2, 2]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "sorted_images_index_100 : Done\n"
     ]
    }
   ],
   "source": [
    "#Threshold 변경해가면서 Original data의 Accuracy가 기존의 88%와 비슷한 threshold를 찾는다\n",
    "#필요한것 sorted_images_index / resnet_trained_model.ckpt / resnet_trainged_model_state.ckpt\n",
    "# segmented_data.pt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# data load\n",
    "batch_size = 100\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                            train=False,download=True,\n",
    "                                            transform=transforms.ToTensor())\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, shuffle=False)\n",
    "\"\"\"\n",
    "original_images = []\n",
    "for images,_ in test_loader:\n",
    "    original_images.append(images)\n",
    "\"\"\"\n",
    "\n",
    "#original_data = torch.stack(original_images, dim=0)\n",
    "segmented_data = torch.load('segmented_data.pt')\n",
    "#augmented_data = original_data\n",
    "sorted_images_index_100 = []\n",
    "\n",
    "# data augmentation\n",
    "with torch.no_grad():\n",
    "    for i in range(100):                               # 100 = len(original_data)\n",
    "        images_batch = segmented_data[i]\n",
    "        for j in range(100):                           # 100 = len(images_batch)\n",
    "            segmented_image = images_batch[j]\n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            object_pixel=0\n",
    "            \n",
    "            for m in range(segmented_image.shape[0]):                   #[1],[2] 였는데 [0],[1]로 바꿈 저번에는 왜됐지?\n",
    "                for n in range(segmented_image.shape[1]):\n",
    "                    if segmented_image[m][n] != 0:\n",
    "                        object_pixel += 1\n",
    "                        \n",
    "            if object_pixel >= 100:\n",
    "                sorted_images_index_100.append((i*batch_size+(j+1)))\n",
    "        #print(i+1,\" batch complete\")\n",
    "        \n",
    "\"\"\"수정된부분\"\"\"\n",
    "print(\"sorted_images_index_100 : Done\")\n",
    "#object_pixel>=150 인 사진들의 index를 기억한 후에 (Not zero-based)\n",
    "#interfere과정에서 해당 index의 사진들만 interfere를 진행\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thr = 50 Done\n"
     ]
    }
   ],
   "source": [
    "sorted_images_index_50 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(100):                               # 100 = len(original_data)\n",
    "        images_batch = segmented_data[i]\n",
    "        for j in range(100):                           # 100 = len(images_batch)\n",
    "            segmented_image = images_batch[j]\n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            object_pixel=0\n",
    "            \n",
    "            for m in range(segmented_image.shape[0]):\n",
    "                for n in range(segmented_image.shape[1]):\n",
    "                    if segmented_image[m][n] != 0:\n",
    "                        object_pixel += 1\n",
    "                        \n",
    "            if object_pixel >= 50:\n",
    "                sorted_images_index_50.append((i*batch_size+(j+1)))\n",
    "       # print(i+1,\" batch complete\")\n",
    "print('Thr = 50 Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thr=150 Done\n"
     ]
    }
   ],
   "source": [
    "sorted_images_index_150 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(100):                               # 100 = len(original_data)\n",
    "        images_batch = segmented_data[i]\n",
    "        for j in range(100):                           # 100 = len(images_batch)\n",
    "            segmented_image = images_batch[j]\n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            object_pixel=0\n",
    "            \n",
    "            for m in range(segmented_image.shape[0]):\n",
    "                for n in range(segmented_image.shape[1]):\n",
    "                    if segmented_image[m][n] != 0:\n",
    "                        object_pixel += 1\n",
    "                        \n",
    "            if object_pixel >= 150:\n",
    "                sorted_images_index_150.append((i*batch_size+(j+1)))\n",
    "        #print(i+1,\" batch complete\")\n",
    "print(\"Thr=150 Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images about Thr=150: 88.69354838709677 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in test_loader:                             #100 = len(augmented_data) = 10000 / batch_size\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)    \n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            #index에 들어있는 사진들만 interfere를 진행\n",
    "            for j in range(batch_size):\n",
    "                if( (i*batch_size)+(j+1) in sorted_images_index_150):     \n",
    "                    total += 1\n",
    "                    if( predicted[j]==labels[j]):\n",
    "                        correct += 1\n",
    "\n",
    "    print('Accuracy of the model on the test images about Thr=150: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Accuracy of the model on the test images about Thr=100: 88.65217391304348 %\n"
     ]
    }
   ],
   "source": [
    "#2. Loading Segmented dataset (our dataset)\n",
    "\"\"\"---------------blue---------------\"\"\"\n",
    "#augmented_data = torch.load('blue_augmented_data.pt')\n",
    "#label_set = []\n",
    "#for _,labels in test_loader:\n",
    "#    label_set.append(labels)\n",
    "#augmented_labels = torch.stack(label_set, dim=0)\n",
    "\n",
    "#print(augmented_data.shape)\n",
    "#print(augmented_labels.shape)\n",
    "\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                            train=False,download=True,\n",
    "                                            transform=transforms.ToTensor())\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Test the model\n",
    "model = torch.load('resnet_trained_model.ckpt')\n",
    "model.load_state_dict(torch.load('resnet_trained_model_state.ckpt'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in test_loader:                             #100 = len(augmented_data) = 10000 / batch_size\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)    \n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            #index에 들어있는 사진들만 interfere를 진행\n",
    "            for j in range(batch_size):\n",
    "                if( (i*batch_size)+(j+1) in sorted_images_index_100):     \n",
    "                    total += 1\n",
    "                    if( predicted[j]==labels[j]):\n",
    "                        correct += 1\n",
    "\n",
    "    print('Accuracy of the model on the test images about Thr=100: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images about Thr=50: 88.61333333333333 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in test_loader:                             #100 = len(augmented_data) = 10000 / batch_size\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)    \n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            #index에 들어있는 사진들만 interfere를 진행\n",
    "            for j in range(batch_size):\n",
    "                if( (i*batch_size)+(j+1) in sorted_images_index_50):     \n",
    "                    total += 1\n",
    "                    if( predicted[j]==labels[j]):\n",
    "                        correct += 1\n",
    "\n",
    "    print('Accuracy of the model on the test images about Thr=50: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5643\n",
      "6213\n",
      "6707\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(sorted_images_index_150))\n",
    "print(len(sorted_images_index_100))\n",
    "print(len(sorted_images_index_50))\n",
    "\n",
    "#print(sorted_images_index_50)\n",
    "\n",
    "sorted_images_index = [sorted_images_index_150,sorted_images_index_100,sorted_images_index_50]\n",
    "print(len(sorted_images_index))\n",
    "#sorted_images_index[0,1,2] = 150 , 100 ,50\n",
    "torch.save(sorted_images_index,'sorted_images_index.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  batch complete\n",
      "2  batch complete\n",
      "3  batch complete\n",
      "4  batch complete\n",
      "5  batch complete\n",
      "6  batch complete\n",
      "7  batch complete\n",
      "8  batch complete\n",
      "9  batch complete\n",
      "10  batch complete\n",
      "11  batch complete\n",
      "12  batch complete\n",
      "13  batch complete\n",
      "14  batch complete\n",
      "15  batch complete\n",
      "16  batch complete\n",
      "17  batch complete\n",
      "18  batch complete\n",
      "19  batch complete\n",
      "20  batch complete\n",
      "21  batch complete\n",
      "22  batch complete\n",
      "23  batch complete\n",
      "24  batch complete\n",
      "25  batch complete\n",
      "26  batch complete\n",
      "27  batch complete\n",
      "28  batch complete\n",
      "29  batch complete\n",
      "30  batch complete\n",
      "31  batch complete\n",
      "32  batch complete\n",
      "33  batch complete\n",
      "34  batch complete\n",
      "35  batch complete\n",
      "36  batch complete\n",
      "37  batch complete\n",
      "38  batch complete\n",
      "39  batch complete\n",
      "40  batch complete\n",
      "41  batch complete\n",
      "42  batch complete\n",
      "43  batch complete\n",
      "44  batch complete\n",
      "45  batch complete\n",
      "46  batch complete\n",
      "47  batch complete\n",
      "48  batch complete\n",
      "49  batch complete\n",
      "50  batch complete\n",
      "51  batch complete\n",
      "52  batch complete\n",
      "53  batch complete\n",
      "54  batch complete\n",
      "55  batch complete\n",
      "56  batch complete\n",
      "57  batch complete\n",
      "58  batch complete\n",
      "59  batch complete\n",
      "60  batch complete\n",
      "61  batch complete\n",
      "62  batch complete\n",
      "63  batch complete\n",
      "64  batch complete\n",
      "65  batch complete\n",
      "66  batch complete\n",
      "67  batch complete\n",
      "68  batch complete\n",
      "69  batch complete\n",
      "70  batch complete\n",
      "71  batch complete\n",
      "72  batch complete\n",
      "73  batch complete\n",
      "74  batch complete\n",
      "75  batch complete\n",
      "76  batch complete\n",
      "77  batch complete\n",
      "78  batch complete\n",
      "79  batch complete\n",
      "80  batch complete\n",
      "81  batch complete\n",
      "82  batch complete\n",
      "83  batch complete\n",
      "84  batch complete\n",
      "85  batch complete\n",
      "86  batch complete\n",
      "87  batch complete\n",
      "88  batch complete\n",
      "89  batch complete\n",
      "90  batch complete\n",
      "91  batch complete\n",
      "92  batch complete\n",
      "93  batch complete\n",
      "94  batch complete\n",
      "95  batch complete\n",
      "96  batch complete\n",
      "97  batch complete\n",
      "98  batch complete\n",
      "99  batch complete\n",
      "100  batch complete\n"
     ]
    }
   ],
   "source": [
    "#Thr 150 / 100 / 50 으로 RGB배경으로 돌리기\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# data load\n",
    "batch_size = 100\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                            train=False,\n",
    "                                            transform=transforms.ToTensor())\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, shuffle=False)\n",
    "\n",
    "original_images = []\n",
    "for images,_ in test_loader:\n",
    "    original_images.append(images)\n",
    "\n",
    "original_data = torch.stack(original_images, dim=0)\n",
    "segmented_data = torch.load('segmented_data.pt')\n",
    "augmented_data = original_data\n",
    "\n",
    "\n",
    "# data augmentation\n",
    "with torch.no_grad():\n",
    "    for i in range(len(original_data)):\n",
    "        images_batch = original_data[i]\n",
    "        for j in range(len(images_batch)):\n",
    "            image = images_batch[j]\n",
    "            \n",
    "            # image 크기 32x32 중 (m,n)번째 pixel\n",
    "            for m in range(image.shape[1]):\n",
    "                for n in range(image.shape[2]):\n",
    "                    \n",
    "                    # segmentation label이 0으로 배경인 pixel에 대해\n",
    "                    # RGB 모두 0으로 설정해 검정 배경으로 만들어줌\n",
    "                    if segmented_data[i][j][m][n] == 0:\n",
    "                        # i번째 batch의 j번째 image의 (m,n) 위치의 RGB intensity값 0으로 설정\n",
    "                        augmented_data[i][j][0][m][n] = 0\n",
    "                        augmented_data[i][j][1][m][n] = 0\n",
    "                        #augmented_data[i][j][2][m][n] = 0\n",
    "        print(i+1,\" batch complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 100, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(augmented_data.shape)\n",
    "torch.save(augmented_data, 'blue_augmented_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc10416dfd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "plt.imshow(transforms.ToPILImage()(augmented_data[33][14]), interpolation=\"bicubic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 100, 3, 32, 32])\n",
      "torch.Size([100, 100])\n",
      "Accuracy of the model on the test images about Thr = 150 & blue: 66.01098706361864 %\n",
      "Accuracy of the model on the test images about Thr = 100 & blue: 63.49589570255915 %\n",
      "Accuracy of the model on the test images about Thr = 50 & blue: 60.92142537647234 %\n"
     ]
    }
   ],
   "source": [
    "# Thr 적용해서 Testing\n",
    "\n",
    "#2. Loading Segmented dataset (our dataset)\n",
    "\"\"\"---------------blue---------------\"\"\"\n",
    "augmented_data = torch.load('blue_augmented_data.pt')\n",
    "label_set = []\n",
    "for _,labels in test_loader:\n",
    "    label_set.append(labels)\n",
    "augmented_labels = torch.stack(label_set, dim=0)\n",
    "\n",
    "print(augmented_data.shape)\n",
    "print(augmented_labels.shape)\n",
    "\n",
    "# Test the model\n",
    "model = torch.load('resnet_trained_model.ckpt')\n",
    "model.load_state_dict(torch.load('resnet_trained_model_state.ckpt'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(augmented_data)):\n",
    "            images = augmented_data[i].to(device)\n",
    "            labels = augmented_labels[i].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)    \n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            #index에 들어있는 사진들만 interfere를 진행\n",
    "            for j in range(batch_size):\n",
    "                if( (i*batch_size)+(j+1) in sorted_images_index_150):     \n",
    "                    total += 1\n",
    "                    if( predicted[j]==labels[j]):\n",
    "                        correct += 1\n",
    "\n",
    "    print('Accuracy of the model on the test images about Thr = 150 & blue: {} %'.format(100 * correct / total))\n",
    "    \n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(augmented_data)):\n",
    "            images = augmented_data[i].to(device)\n",
    "            labels = augmented_labels[i].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)    \n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            #index에 들어있는 사진들만 interfere를 진행\n",
    "            for j in range(batch_size):\n",
    "                if( (i*batch_size)+(j+1) in sorted_images_index_100):     \n",
    "                    total += 1\n",
    "                    if( predicted[j]==labels[j]):\n",
    "                        correct += 1\n",
    "\n",
    "    print('Accuracy of the model on the test images about Thr = 100 & blue: {} %'.format(100 * correct / total))\n",
    "    \n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(augmented_data)):\n",
    "            images = augmented_data[i].to(device)\n",
    "            labels = augmented_labels[i].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)    \n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            #index에 들어있는 사진들만 interfere를 진행\n",
    "            for j in range(batch_size):\n",
    "                if( (i*batch_size)+(j+1) in sorted_images_index_50):     \n",
    "                    total += 1\n",
    "                    if( predicted[j]==labels[j]):\n",
    "                        correct += 1\n",
    "\n",
    "    print('Accuracy of the model on the test images about Thr = 50 & blue: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 100, 3, 32, 32])\n",
      "torch.Size([100, 100])\n",
      "Accuracy of the model on the test images about Thr = 150 & green: 72.37285132021974 %\n",
      "Accuracy of the model on the test images about Thr = 100 & green: 70.17543859649123 %\n",
      "Accuracy of the model on the test images about Thr = 50 & green: 67.73520202773221 %\n"
     ]
    }
   ],
   "source": [
    "# Thr 적용해서 Testing\n",
    "\n",
    "#2. Loading Segmented dataset (our dataset)\n",
    "\"\"\"---------------green---------------\"\"\"\n",
    "augmented_data = torch.load('green_augmented_data.pt')\n",
    "label_set = []\n",
    "for _,labels in test_loader:\n",
    "    label_set.append(labels)\n",
    "augmented_labels = torch.stack(label_set, dim=0)\n",
    "\n",
    "print(augmented_data.shape)\n",
    "print(augmented_labels.shape)\n",
    "\n",
    "# Test the model\n",
    "model = torch.load('resnet_trained_model.ckpt')\n",
    "model.load_state_dict(torch.load('resnet_trained_model_state.ckpt'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(augmented_data)):\n",
    "            images = augmented_data[i].to(device)\n",
    "            labels = augmented_labels[i].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)    \n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            #index에 들어있는 사진들만 interfere를 진행\n",
    "            for j in range(batch_size):\n",
    "                if( (i*batch_size)+(j+1) in sorted_images_index_150):     \n",
    "                    total += 1\n",
    "                    if( predicted[j]==labels[j]):\n",
    "                        correct += 1\n",
    "\n",
    "    print('Accuracy of the model on the test images about Thr = 150 & green: {} %'.format(100 * correct / total))\n",
    "    \n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(augmented_data)):\n",
    "            images = augmented_data[i].to(device)\n",
    "            labels = augmented_labels[i].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)    \n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            #index에 들어있는 사진들만 interfere를 진행\n",
    "            for j in range(batch_size):\n",
    "                if( (i*batch_size)+(j+1) in sorted_images_index_100):     \n",
    "                    total += 1\n",
    "                    if( predicted[j]==labels[j]):\n",
    "                        correct += 1\n",
    "\n",
    "    print('Accuracy of the model on the test images about Thr = 100 & green: {} %'.format(100 * correct / total))\n",
    "    \n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(augmented_data)):\n",
    "            images = augmented_data[i].to(device)\n",
    "            labels = augmented_labels[i].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)    \n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            #index에 들어있는 사진들만 interfere를 진행\n",
    "            for j in range(batch_size):\n",
    "                if( (i*batch_size)+(j+1) in sorted_images_index_50):     \n",
    "                    total += 1\n",
    "                    if( predicted[j]==labels[j]):\n",
    "                        correct += 1\n",
    "\n",
    "    print('Accuracy of the model on the test images about Thr = 50 & green: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 100, 3, 32, 32])\n",
      "torch.Size([100, 100])\n",
      "Accuracy of the model on the test images about Thr = 150 & red: 53.854332801701226 %\n",
      "Accuracy of the model on the test images about Thr = 100 & red: 51.61757605021729 %\n",
      "Accuracy of the model on the test images about Thr = 50 & red: 50.24601162964068 %\n"
     ]
    }
   ],
   "source": [
    "# Thr 적용해서 Testing\n",
    "\n",
    "#2. Loading Segmented dataset (our dataset)\n",
    "\"\"\"---------------red---------------\"\"\"\n",
    "augmented_data = torch.load('red_augmented_data.pt')\n",
    "label_set = []\n",
    "for _,labels in test_loader:\n",
    "    label_set.append(labels)\n",
    "augmented_labels = torch.stack(label_set, dim=0)\n",
    "\n",
    "print(augmented_data.shape)\n",
    "print(augmented_labels.shape)\n",
    "\n",
    "# Test the model\n",
    "model = torch.load('resnet_trained_model.ckpt')\n",
    "model.load_state_dict(torch.load('resnet_trained_model_state.ckpt'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(augmented_data)):\n",
    "            images = augmented_data[i].to(device)\n",
    "            labels = augmented_labels[i].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)    \n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            #index에 들어있는 사진들만 interfere를 진행\n",
    "            for j in range(batch_size):\n",
    "                if( (i*batch_size)+(j+1) in sorted_images_index_150):     \n",
    "                    total += 1\n",
    "                    if( predicted[j]==labels[j]):\n",
    "                        correct += 1\n",
    "\n",
    "    print('Accuracy of the model on the test images about Thr = 150 & red: {} %'.format(100 * correct / total))\n",
    "    \n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(augmented_data)):\n",
    "            images = augmented_data[i].to(device)\n",
    "            labels = augmented_labels[i].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)    \n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            #index에 들어있는 사진들만 interfere를 진행\n",
    "            for j in range(batch_size):\n",
    "                if( (i*batch_size)+(j+1) in sorted_images_index_100):     \n",
    "                    total += 1\n",
    "                    if( predicted[j]==labels[j]):\n",
    "                        correct += 1\n",
    "\n",
    "    print('Accuracy of the model on the test images about Thr = 100 & red: {} %'.format(100 * correct / total))\n",
    "    \n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(augmented_data)):\n",
    "            images = augmented_data[i].to(device)\n",
    "            labels = augmented_labels[i].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)    \n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            #index에 들어있는 사진들만 interfere를 진행\n",
    "            for j in range(batch_size):\n",
    "                if( (i*batch_size)+(j+1) in sorted_images_index_50):     \n",
    "                    total += 1\n",
    "                    if( predicted[j]==labels[j]):\n",
    "                        correct += 1\n",
    "\n",
    "    print('Accuracy of the model on the test images about Thr = 50 & red: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 100, 3, 32, 32])\n",
      "torch.Size([100, 100])\n",
      "Accuracy of the model on the test images about Thr = 150 & black: 63.06928938507886 %\n",
      "Accuracy of the model on the test images about Thr = 100 & black: 60.63093513600515 %\n",
      "Accuracy of the model on the test images about Thr = 50 & black: 58.17802296108543 %\n"
     ]
    }
   ],
   "source": [
    "# Thr 적용해서 Testing\n",
    "\n",
    "#2. Loading Segmented dataset (our dataset)\n",
    "\"\"\"---------------red---------------\"\"\"\n",
    "augmented_data = torch.load('black_augmented_data.pt')\n",
    "label_set = []\n",
    "for _,labels in test_loader:\n",
    "    label_set.append(labels)\n",
    "augmented_labels = torch.stack(label_set, dim=0)\n",
    "\n",
    "print(augmented_data.shape)\n",
    "print(augmented_labels.shape)\n",
    "\n",
    "# Test the model\n",
    "model = torch.load('resnet_trained_model.ckpt')\n",
    "model.load_state_dict(torch.load('resnet_trained_model_state.ckpt'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(augmented_data)):\n",
    "            images = augmented_data[i].to(device)\n",
    "            labels = augmented_labels[i].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)    \n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            #index에 들어있는 사진들만 interfere를 진행\n",
    "            for j in range(batch_size):\n",
    "                if( (i*batch_size)+(j+1) in sorted_images_index_150):     \n",
    "                    total += 1\n",
    "                    if( predicted[j]==labels[j]):\n",
    "                        correct += 1\n",
    "\n",
    "    print('Accuracy of the model on the test images about Thr = 150 & black: {} %'.format(100 * correct / total))\n",
    "    \n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(augmented_data)):\n",
    "            images = augmented_data[i].to(device)\n",
    "            labels = augmented_labels[i].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)    \n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            #index에 들어있는 사진들만 interfere를 진행\n",
    "            for j in range(batch_size):\n",
    "                if( (i*batch_size)+(j+1) in sorted_images_index_100):     \n",
    "                    total += 1\n",
    "                    if( predicted[j]==labels[j]):\n",
    "                        correct += 1\n",
    "\n",
    "    print('Accuracy of the model on the test images about Thr = 100 & black: {} %'.format(100 * correct / total))\n",
    "    \n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(augmented_data)):\n",
    "            images = augmented_data[i].to(device)\n",
    "            labels = augmented_labels[i].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)    \n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            #index에 들어있는 사진들만 interfere를 진행\n",
    "            for j in range(batch_size):\n",
    "                if( (i*batch_size)+(j+1) in sorted_images_index_50):     \n",
    "                    total += 1\n",
    "                    if( predicted[j]==labels[j]):\n",
    "                        correct += 1\n",
    "\n",
    "    print('Accuracy of the model on the test images about Thr = 50 & black: {} %'.format(100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
